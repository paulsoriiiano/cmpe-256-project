{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec8e6c6",
   "metadata": {},
   "source": [
    "# Alternating Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a07b0",
   "metadata": {},
   "source": [
    "## 1. Import and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1bb47df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (2380730, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2380730 entries, 0 to 2380729\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count    Dtype\n",
      "---  ------   --------------    -----\n",
      " 0   user_id  2380730 non-null  int64\n",
      " 1   item_id  2380730 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 36.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train_2_long.csv\")\n",
    "print(f\"Dataframe shape: {df.shape}\")\n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0315b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries before dropping duplicates: 2380730\n",
      "Number of entries after dropping duplicates: 2380730\n"
     ]
    }
   ],
   "source": [
    "len_before = df.shape[0]\n",
    "print(f\"Number of entries before dropping duplicates: {len_before}\")\n",
    "df = df.drop_duplicates()\n",
    "len_after = df.shape[0]\n",
    "print(f\"Number of entries after dropping duplicates: {len_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "635def18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 52643 unique users.\n",
      "There are 91599 unique items.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df['user_id'].nunique()} unique users.\")\n",
    "print(f\"There are {df['item_id'].nunique()} unique items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "157eaace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average user interacted with 45 items.\n",
      "\n",
      "User interactions stats:\n",
      "count    52643.000000\n",
      "mean        45.224056\n",
      "std         77.958253\n",
      "min         16.000000\n",
      "25%         19.000000\n",
      "50%         26.000000\n",
      "75%         45.000000\n",
      "max      10682.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "user_interactions = df[\"user_id\"].value_counts()\n",
    "print(f\"The average user interacted with {int(user_interactions.mean())} items.\\n\")\n",
    "print(f\"User interactions stats:\\n{user_interactions.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc513cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average item has 25 interactions.\n",
      "\n",
      "User interactions stats:\n",
      "count    91599.000000\n",
      "mean        25.990786\n",
      "std         38.397318\n",
      "min          1.000000\n",
      "25%         10.000000\n",
      "50%         15.000000\n",
      "75%         28.000000\n",
      "max       1741.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "item_interactions = df[\"item_id\"].value_counts()\n",
    "print(f\"The average item has {int(item_interactions.mean())} interactions.\\n\")\n",
    "print(f\"User interactions stats:\\n{item_interactions.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b297c880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>150</td>\n",
       "      <td>9566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19001</th>\n",
       "      <td>150</td>\n",
       "      <td>5357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19002</th>\n",
       "      <td>150</td>\n",
       "      <td>13171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19003</th>\n",
       "      <td>150</td>\n",
       "      <td>13172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>150</td>\n",
       "      <td>21470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29677</th>\n",
       "      <td>150</td>\n",
       "      <td>21471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29678</th>\n",
       "      <td>150</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29679</th>\n",
       "      <td>150</td>\n",
       "      <td>21472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29680</th>\n",
       "      <td>150</td>\n",
       "      <td>7116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10682 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id\n",
       "18999      150     9566\n",
       "19000      150       60\n",
       "19001      150     5357\n",
       "19002      150    13171\n",
       "19003      150    13172\n",
       "...        ...      ...\n",
       "29676      150    21470\n",
       "29677      150    21471\n",
       "29678      150      552\n",
       "29679      150    21472\n",
       "29680      150     7116\n",
       "\n",
       "[10682 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_active_user = user_interactions.index[0]\n",
    "df[df[\"user_id\"] == most_active_user]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebac74",
   "metadata": {},
   "source": [
    "## 2. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc596f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add implicit value = 1.0 (positive interaction)\n",
    "# df[\"value\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33ba8c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id\n",
       "0        0    28261\n",
       "1        0      388\n",
       "2        0     5731\n",
       "3        0      401\n",
       "4        0    28284"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64516691",
   "metadata": {},
   "source": [
    "### 2.1. Encoding user and items\n",
    "`implicit` requires zero-based IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a26cce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID min: 0, max: 52642\n",
      "Item ID min: 6, max: 91604\n"
     ]
    }
   ],
   "source": [
    "# Check ID ranges\n",
    "print(f\"User ID min: {df['user_id'].min()}, max: {df['user_id'].max()}\")\n",
    "print(f\"Item ID min: {df['item_id'].min()}, max: {df['item_id'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bfbbdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map IDs to zero-based\n",
    "user_map = {uid: u_idx for u_idx, uid in enumerate(sorted(df[\"user_id\"].unique()))}\n",
    "item_map = {iid: i_idx for i_idx, iid in enumerate(sorted(df[\"item_id\"].unique()))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3bfb2b",
   "metadata": {},
   "source": [
    "### 2.2. Function to convert to sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e5abd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def df_to_sparse(df):\n",
    "    \"\"\" Function that converts a dataframe to a sparse matrix. \"\"\"\n",
    "    rows = df[\"user_id\"].map(user_map)\n",
    "    cols = df[\"item_id\"].map(item_map)\n",
    "    vals = np.ones(len(df))\n",
    "\n",
    "    matrix = coo_matrix((vals, (rows, cols)),\n",
    "                        shape=(len(user_map), len(item_map)))\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6eb31",
   "metadata": {},
   "source": [
    "## 3. Split data into training and testing\n",
    "using `sklearn.model selection.train_test_split`\n",
    "\n",
    "* Split user-item interactions into training and testing.\n",
    "* Ensures a more realistic evaluation when generalizing to new users or items.\n",
    "\n",
    "For every user:\n",
    "* Perform `train_test_split` on the items it has interacted with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0cfe9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define group\n",
    "user_groups = df.groupby(\"user_id\")\n",
    "\n",
    "# Store splits\n",
    "train_pairs, test_pairs = [], []\n",
    "\n",
    "# Iterate through groups\n",
    "for user, items in user_groups:\n",
    "    train, test = train_test_split(items, test_size=0.2, random_state=17)\n",
    "    train_pairs.append(train)\n",
    "    test_pairs.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f7acf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1881725, 2) (499005, 2)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Turn lists into dataframes\n",
    "train_df = pd.concat(train_pairs)\n",
    "test_df = pd.concat(test_pairs)\n",
    "\n",
    "# Check dataframe shapes\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# Make sure split is done properly\n",
    "print(train_df.shape[0] + test_df.shape[0] == df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3908810",
   "metadata": {},
   "source": [
    "## 4. Train ALS model\n",
    "Alternating Least Squares (ALS) is a matrix factorization algorithm which typically works well for implicit feedback data, such as user-item interactions, as seen in this [Netflix Prize and SVD](http://buzzard.ups.edu/courses/2014spring/420projects/math420-UPS-spring-2014-gower-netflix-SVD.pdf) paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d17ca8",
   "metadata": {},
   "source": [
    "### 4.1. Create csr_matrix representations for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41f88a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 1881725 stored elements and shape (52643, 91599)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training matrix\n",
    "train_csr = df_to_sparse(train_df).tocsr()\n",
    "train_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c16a1ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 499005 stored elements and shape (52643, 91599)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test matrix\n",
    "test_csr = df_to_sparse(test_df).tocsr()\n",
    "test_csr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd01ec2",
   "metadata": {},
   "source": [
    "### 4.2. Train model\n",
    "Hyperparameters used for initial training:\n",
    "* `factors` = 50: the number of latent factors in for decomposition\n",
    "* `regularization` = 0.1: the regularization parameter ($\\lambda$)\n",
    "* `iterations` = 20: the number of training iterations\n",
    "* `alpha` = 1.0: the weights given for positive interactions\n",
    "* `use_cg` = True: used a faster solver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cfcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d6f981926144eba5d1cd96317868af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "model = AlternatingLeastSquares(\n",
    "    factors=50,             # hyperparameter (latent factors)\n",
    "    regularization=0.1,     # hyperparameter ()\n",
    "    iterations=20,          # hyperparameter (epochs)\n",
    "    alpha=1.0               # hyperparameter (alpha)\n",
    "    use_cg=True,\n",
    "    calculate_training_loss=True\n",
    ")\n",
    "\n",
    "model.fit(train_csr, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6af264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User factors shape: (52643, 100)\n",
      "Item factors shape: (91599, 100)\n"
     ]
    }
   ],
   "source": [
    "# Check matrix decomposition shapes\n",
    "print(\"User factors shape:\", model.user_factors.shape)\n",
    "print(\"Item factors shape:\", model.item_factors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8435d",
   "metadata": {},
   "source": [
    "## 5. Recommend top 20 items for users in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ef182",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fd640533",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20 # top 20, NDCG@K\n",
    "\n",
    "recommended_items = model.recommend_all(train_csr, \n",
    "                                        N=K,\n",
    "                                        filter_already_liked_items=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "69158eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model recommended top 20 items for ALL users.\n",
    "len(recommended_items) == df[\"user_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d85a966",
   "metadata": {},
   "source": [
    "## 6. Evaluate with NDCG@20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7389846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean NDCG@20 = 0.0556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def batched_ndcg_at_k(recommended_items, test_matrix, k=20, batch_size=1000):\n",
    "    num_users = test_matrix.shape[0]\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for start in range(0, num_users, batch_size):\n",
    "        end = min(start + batch_size, num_users)\n",
    "\n",
    "        # Extract true relevance for the batch\n",
    "        true_batch = test_matrix[start:end].toarray()\n",
    "\n",
    "        # Build predicted score matrix for this batch\n",
    "        pred_batch = np.zeros_like(true_batch)\n",
    "        for i, user_idx in enumerate(range(start, end)):\n",
    "            items = recommended_items[user_idx]\n",
    "            pred_batch[i, items[:k]] = 1.0 / (np.arange(1, k + 1))  # rank weighting\n",
    "\n",
    "        # Compute vectorized NDCG for the batch\n",
    "        batch_ndcg = ndcg_score(true_batch, pred_batch, k=k)\n",
    "        ndcg_scores.append(batch_ndcg)\n",
    "\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "# Example usage\n",
    "mean_ndcg = batched_ndcg_at_k(recommended_items, test_csr, k=K, batch_size=1000)\n",
    "print(f\"Mean NDCG@20 = {mean_ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ce849",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4177704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import ndcg_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Store NCDG@20 scores for each user in the test set\n",
    "# ndcg_scores = []\n",
    "\n",
    "# for user_idx in range(test_csr.shape[0]):\n",
    "#     true_items = test_csr[user_idx].toarray().ravel()\n",
    "\n",
    "#     if len(true_items) == 0:\n",
    "#         print(f\"Skipping user index: {user_idx}\")\n",
    "#         continue\n",
    "\n",
    "#     # Predicted scores\n",
    "#     pred_scores = np.zeros_like(true_items)\n",
    "#     pred_scores[recommended_items[user_idx]] = 1.0 / (np.arange(1, 21)) # weighted ranking\n",
    "\n",
    "\n",
    "#     ndcg = ndcg_score([true_items], [pred_scores], k=K)\n",
    "#     ndcg_scores.append(ndcg)\n",
    "\n",
    "# print(f\"Average NDCG Score: {np.mean(ndcg_scores): 0.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ca44b056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  13,  114,  527, 4938,  387,  432, 2374,  373,  673,  975,  379,\n",
       "         11,  136, 4956,  374, 5964, 1364,   90,  447, 5182], dtype=int32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_items[user_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c2a01bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  395,  5725, 22030, 29775]),)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(true_items == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161cf19",
   "metadata": {},
   "source": [
    "## 7. Write output file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d2adf",
   "metadata": {},
   "source": [
    "### 7.1. Create reverse maps for user_idx and item_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4924da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_user_map = {user_idx: user_id for user_id, user_idx in user_map.items()}\n",
    "reverse_item_map = {item_idx: item_id for item_id, item_idx in item_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5454c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"als100f_50e.txt\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for user_idx, item_indices in enumerate(recommended_items):\n",
    "        user_id = reverse_user_map[user_idx]\n",
    "        item_ids = [str(reverse_item_map[i]) for i in item_indices]\n",
    "        f.write(f\"{user_id} {' '.join(item_ids)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535e349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19,\n",
       " 120,\n",
       " 533,\n",
       " 4944,\n",
       " 393,\n",
       " 438,\n",
       " 2380,\n",
       " 379,\n",
       " 679,\n",
       " 981,\n",
       " 385,\n",
       " 17,\n",
       " 142,\n",
       " 4962,\n",
       " 380,\n",
       " 5970,\n",
       " 1370,\n",
       " 96,\n",
       " 453,\n",
       " 5188]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map all item_idx back to original item_id\n",
    "[reverse_item_map.get(item, item) for item in recommended_items[0]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac011df",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
