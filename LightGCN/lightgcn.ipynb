{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6600dec9",
   "metadata": {},
   "source": [
    "# LightGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd6853d",
   "metadata": {},
   "source": [
    "## 1. Set up and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393ea19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:51:49) [Clang 16.0.6 ]\n",
      "Numpy version: 1.26.4\n",
      "Pandas version: 2.3.3\n",
      "Tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import ndcg_at_k\n",
    "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "from recommenders.utils.notebook_utils import store_metadata\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385e2c5",
   "metadata": {},
   "source": [
    "### 1.1. Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 items\n",
    "TOP_K = 20\n",
    "\n",
    "# Model initial hyperparameters\n",
    "EMBED_SIZE = 64\n",
    "N_LAYERS = 3\n",
    "\n",
    "BATCH_SIZE = 16384\n",
    "DECAY = 0.0001\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.005\n",
    "EVAL_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1465c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"lightgcn.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69bb03",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a5fcd",
   "metadata": {},
   "source": [
    "### 2.1. Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719b2716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID\n",
       "0       0   28261\n",
       "1       0     388\n",
       "2       0    5731\n",
       "3       0     401\n",
       "4       0   28284"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../data/train_2_long.csv\",\n",
    "    header = 0,\n",
    "    names = [\"userID\", \"itemID\"]\n",
    "    )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd9bcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28261</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5731</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>401</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28284</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0       0   28261     1.0\n",
       "1       0     388     1.0\n",
       "2       0    5731     1.0\n",
       "3       0     401     1.0\n",
       "4       0   28284     1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add rating column\n",
    "df[\"rating\"] = 1.0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c4910",
   "metadata": {},
   "source": [
    "### 2.2. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7683e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(df, ratio=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f8cd7",
   "metadata": {},
   "source": [
    "### 2.3. Process data\n",
    "Using `ImplicitCF` class\n",
    "* creates an adjacency matrix for user-item graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b109a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data object\n",
    "data = ImplicitCF(train=train, test=test, seed=DEFAULT_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a1781",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb56c1e",
   "metadata": {},
   "source": [
    "### 3.1. Prepare hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf851cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = prepare_hparams(yaml_file,\n",
    "                          n_layers=N_LAYERS,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          decay=DECAY,\n",
    "                          epochs=EPOCHS,\n",
    "                          learning_rate=LEARNING_RATE,\n",
    "                          eval_epoch=EVAL_EPOCHS,\n",
    "                          top_k=TOP_K,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32d5f0",
   "metadata": {},
   "source": [
    "### 3.2. Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71645b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764389641.709805 19577641 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "model = LightGCN(hparams, data, seed=DEFAULT_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d78a7f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (train)2431.0s: train loss = 0.20171 = (mf)0.20055 + (embed)0.00117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Timer() \u001b[38;5;28;01mas\u001b[39;00m train_time:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTook \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_time\u001b[38;5;241m.\u001b[39minterval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds for training.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/school/grad/Fall_25/CMPE256/cmpe-256-project/.venv/lib/python3.10/site-packages/recommenders/models/deeprec/models/graphrec/lightgcn.py:219\u001b[0m, in \u001b[0;36mLightGCN.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batch):\n\u001b[1;32m    218\u001b[0m     users, pos_items, neg_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_loader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 219\u001b[0m     _, batch_loss, batch_mf_loss, batch_emb_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmf_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_loss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musers\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_items\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_items\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss \u001b[38;5;241m/\u001b[39m n_batch\n\u001b[1;32m    228\u001b[0m     mf_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_mf_loss \u001b[38;5;241m/\u001b[39m n_batch\n",
      "File \u001b[0;32m~/Documents/school/grad/Fall_25/CMPE256/cmpe-256-project/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py:977\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    974\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    980\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/Documents/school/grad/Fall_25/CMPE256/cmpe-256-project/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py:1220\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1220\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/school/grad/Fall_25/CMPE256/cmpe-256-project/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py:1400\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1397\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/Documents/school/grad/Fall_25/CMPE256/cmpe-256-project/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py:1407\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1406\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1408\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1409\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/Documents/school/grad/Fall_25/CMPE256/cmpe-256-project/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py:1390\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1388\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1390\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/school/grad/Fall_25/CMPE256/cmpe-256-project/.venv/lib/python3.10/site-packages/tensorflow/python/client/session.py:1483\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1482\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1483\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit()\n",
    "\n",
    "print(f\"Took {train_time.interval} seconds for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b38a0",
   "metadata": {},
   "source": [
    "## 4. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f27dfc",
   "metadata": {},
   "source": [
    "### 4.1. Generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_recs = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "top_k_recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ed99c",
   "metadata": {},
   "source": [
    "### 4.2. Evaluate using NDCG@20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ndcg = ndcg_at_k(test, top_k_recs, k=TOP_K)\n",
    "\n",
    "print(f\"NCDG@20:\\t{eval_ndcg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b349f9",
   "metadata": {},
   "source": [
    "## 5. Tune model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5de61",
   "metadata": {},
   "source": [
    "### 5.1. Start with regularization and learning rate search on fixed architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(batch_size, decay, emb_dim, epochs, layers, lr):\n",
    "    \"\"\"Evaluate a LightGCN model given hyperparameters.\"\"\"\n",
    "\n",
    "    hparams = (yaml_file,\n",
    "                embed_size=embed_dim,\n",
    "                n_layers=layers,\n",
    "                batch_size=batch_size,\n",
    "                decay=decay,\n",
    "                epochs=epochs,\n",
    "                learning_rate=lr,\n",
    "                eval_epoch=EVAL_EPOCHS,\n",
    "                top_k=TOP_K)\n",
    "\n",
    "    model = LightGCN(hparams, data, seed=SEED)\n",
    "    model.fit()\n",
    "\n",
    "    recs = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "    ndcg = ndcg_at_k(test, recs, k=TOP_K)\n",
    "\n",
    "    return (batch_size, decay, emb_dim, epochs, layers, lr, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed architecture\n",
    "BATCH_SIZE = 8192\n",
    "EMBED_SIZE = 64\n",
    "N_LAYERS = 2\n",
    "\n",
    "# Grid search\n",
    "LR = [5e-4, 1e-3, 2e-3]     # learning rate\n",
    "L2 = [1e-6, 1e-5, 1e-4]     # decay\n",
    "\n",
    "# Create all LR and L2 combos\n",
    "lr_l2_combos = list(itertools.product(LR, L2))\n",
    "\n",
    "results = []\n",
    "\n",
    "for (lr, l2) in lr_l2_combos:\n",
    "    # result = evaluate_model(\n",
    "    #     batch_size=BATCH_SIZE,\n",
    "    #     decay=l2,\n",
    "    #     emb_dim=EMBED_SIZE,\n",
    "    #     epochs=20,\n",
    "    #     layers=N_LAYERS,\n",
    "    #     lr=lr\n",
    "    # )\n",
    "\n",
    "    # results.append()\n",
    "    print(lr, l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aae858",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cur_params = max(results, key=lambda x: x[:-1])\n",
    "BEST_DECAY = best_cur_params[1]\n",
    "BEST_LR = best_cur_params[5]\n",
    "best_cur_ndcg = best_cur_params[-1]\n",
    "\n",
    "print(f\"decay: {BEST_DECAY}, lr: {BEST_LR}, ndcg: {best_cur_ndcg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f732436d",
   "metadata": {},
   "source": [
    "### 5.2. Find best embedding size and layers with fixed regularization and decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf209dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZES = [32, 64]\n",
    "LAYERS = [1, 2]\n",
    "\n",
    "emb_layers_combos = list(itertools.product(EMBED_SIZES, LAYERS))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fba76",
   "metadata": {},
   "source": [
    "## 6. Recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53517d7e",
   "metadata": {},
   "source": [
    "### 6.1. Train model with best params and on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 21:04:56.832146: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-28 21:04:56.832166: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.python.framework import test_util as tf_test\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# print(tf_test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc0ef9",
   "metadata": {},
   "source": [
    "### 6.2 Generate predictions file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a4741a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
