{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Recommender System (ItemKNN)\n",
                "\n",
                "This notebook implements an Item-based K-Nearest Neighbors recommender system."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from scipy.sparse import csr_matrix\n",
                "from sklearn.preprocessing import normalize\n",
                "import sys\n",
                "import time"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Loading\n",
                "Function to load the dataset into a sparse CSR matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(file_path):\n",
                "    print(\"Loading data...\")\n",
                "    rows = []\n",
                "    cols = []\n",
                "    data = []\n",
                "    \n",
                "    max_user_id = 0\n",
                "    max_item_id = 0\n",
                "    \n",
                "    with open(file_path, 'r') as f:\n",
                "        for line in f:\n",
                "            parts = list(map(int, line.strip().split()))\n",
                "            if not parts:\n",
                "                continue\n",
                "            user_id = parts[0]\n",
                "            items = parts[1:]\n",
                "            \n",
                "            if not items:\n",
                "                continue\n",
                "                \n",
                "            max_user_id = max(max_user_id, user_id)\n",
                "            for item_id in items:\n",
                "                rows.append(user_id)\n",
                "                cols.append(item_id)\n",
                "                data.append(1)\n",
                "                max_item_id = max(max_item_id, item_id)\n",
                "                \n",
                "    # Create CSR matrix\n",
                "    # Shape is (max_user_id + 1, max_item_id + 1)\n",
                "    X = csr_matrix((data, (rows, cols)), shape=(max_user_id + 1, max_item_id + 1))\n",
                "    print(f\"Data loaded. Shape: {X.shape}, Non-zeros: {X.nnz}\")\n",
                "    return X"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Similarity Computation\n",
                "Compute item-item cosine similarity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_similarity(X, k=200):\n",
                "    print(\"Computing similarity matrix...\")\n",
                "    # Normalize rows of X^T (which are items) to compute cosine similarity\n",
                "    # Cosine similarity between item i and j is (X_i . X_j) / (|X_i| |X_j|)\n",
                "    # This is equivalent to normalizing columns of X, then computing X^T X\n",
                "    \n",
                "    # We want item-item similarity.\n",
                "    # X is User x Item.\n",
                "    # Normalize columns (items) to unit norm\n",
                "    X_norm = normalize(X, norm='l2', axis=0) # Normalize columns\n",
                "    \n",
                "    start_time = time.time()\n",
                "    # Transpose X_norm to get (I, U)\n",
                "    X_T = X_norm.T\n",
                "    \n",
                "    # Sim = X_T * X_norm\n",
                "    # This computes cosine similarity\n",
                "    Sim = X_T.dot(X_norm)\n",
                "    \n",
                "    # Zero out diagonal\n",
                "    Sim.setdiag(0)\n",
                "    \n",
                "    print(f\"Similarity computed. Shape: {Sim.shape}, Non-zeros: {Sim.nnz}\")\n",
                "    print(f\"Time taken: {time.time() - start_time:.2f}s\")\n",
                "    \n",
                "    return Sim"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Recommendation Generation\n",
                "Generate top-k recommendations for each user."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_recommendations(X, Sim, output_file, top_k=20):\n",
                "    print(\"Generating recommendations...\")\n",
                "    # Scores = X * Sim\n",
                "    # X is (U, I), Sim is (I, I) -> Scores is (U, I)\n",
                "    \n",
                "    n_users = X.shape[0]\n",
                "    batch_size = 1000\n",
                "    \n",
                "    with open(output_file, 'w') as f:\n",
                "        for start_idx in range(0, n_users, batch_size):\n",
                "            end_idx = min(start_idx + batch_size, n_users)\n",
                "            \n",
                "            # Get user batch\n",
                "            user_batch = X[start_idx:end_idx]\n",
                "            \n",
                "            # Compute scores\n",
                "            scores_batch = user_batch.dot(Sim)\n",
                "            \n",
                "            # Convert to dense for sorting (batch is small enough)\n",
                "            scores_dense = scores_batch.toarray()\n",
                "            \n",
                "            # Mask out items already interacted with\n",
                "            mask = user_batch.toarray() > 0\n",
                "            scores_dense[mask] = -np.inf\n",
                "            \n",
                "            # Get top K\n",
                "            top_items = np.argpartition(scores_dense, -top_k, axis=1)[:, -top_k:]\n",
                "            \n",
                "            # The top_items are not sorted, so we need to sort them\n",
                "            rows = np.arange(scores_dense.shape[0])[:, None]\n",
                "            top_scores = scores_dense[rows, top_items]\n",
                "            \n",
                "            # Sort indices based on scores descending\n",
                "            sort_ind = np.argsort(top_scores, axis=1)[:, ::-1]\n",
                "            \n",
                "            final_recs = top_items[rows, sort_ind]\n",
                "            \n",
                "            # Write to file\n",
                "            for i, u_id in enumerate(range(start_idx, end_idx)):\n",
                "                recs = final_recs[i]\n",
                "                # Format: UserID item1 item2 ... item20\n",
                "                f.write(f\"{u_id} {' '.join(map(str, recs))}\\n\")\n",
                "                \n",
                "            if start_idx % 5000 == 0:\n",
                "                print(f\"Processed {start_idx} users...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Execution\n",
                "Run the pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading data...\n",
                        "Data loaded. Shape: (52643, 91605), Non-zeros: 2380730\n",
                        "Computing similarity matrix...\n",
                        "Similarity computed. Shape: (91605, 91605), Non-zeros: 330335859\n",
                        "Time taken: 9.70s\n",
                        "Generating recommendations...\n",
                        "Processed 0 users...\n",
                        "Processed 5000 users...\n",
                        "Processed 10000 users...\n",
                        "Processed 15000 users...\n",
                        "Processed 20000 users...\n",
                        "Processed 25000 users...\n",
                        "Processed 30000 users...\n",
                        "Processed 35000 users...\n",
                        "Processed 40000 users...\n",
                        "Processed 45000 users...\n",
                        "Processed 50000 users...\n",
                        "Done!\n"
                    ]
                }
            ],
            "source": [
                "input_file = 'train-2.txt'\n",
                "output_file = 'output_KNN.txt'\n",
                "\n",
                "X = load_data(input_file)\n",
                "Sim = compute_similarity(X)\n",
                "generate_recommendations(X, Sim, output_file)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verification\n",
                "Check the output file for correctness."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Verifying output...\n",
                        "Verification successful! Verified 52643 users.\n"
                    ]
                }
            ],
            "source": [
                "def verify_output(output_file, train_file):\n",
                "    print(\"Verifying output...\")\n",
                "    \n",
                "    # Load training data to check for duplicates\n",
                "    train_interactions = {}\n",
                "    with open(train_file, 'r') as f:\n",
                "        for line in f:\n",
                "            parts = list(map(int, line.strip().split()))\n",
                "            if not parts: continue\n",
                "            u_id = parts[0]\n",
                "            items = set(parts[1:])\n",
                "            train_interactions[u_id] = items\n",
                "            \n",
                "    num_users = 0\n",
                "    with open(output_file, 'r') as f:\n",
                "        for line in f:\n",
                "            parts = list(map(int, line.strip().split()))\n",
                "            if not parts: continue\n",
                "            \n",
                "            u_id = parts[0]\n",
                "            recs = parts[1:]\n",
                "            \n",
                "            if len(recs) != 20:\n",
                "                print(f\"Error: User {u_id} has {len(recs)} recommendations instead of 20.\")\n",
                "                return\n",
                "            \n",
                "            if len(set(recs)) != 20:\n",
                "                print(f\"Error: User {u_id} has duplicate recommendations.\")\n",
                "                return\n",
                "                \n",
                "            # Check if recommended items are in training set\n",
                "            if u_id in train_interactions:\n",
                "                train_items = train_interactions[u_id]\n",
                "                for item in recs:\n",
                "                    if item in train_items:\n",
                "                        print(f\"Error: User {u_id} recommended item {item} which is in training set.\")\n",
                "                        return\n",
                "            \n",
                "            num_users += 1\n",
                "            \n",
                "    print(f\"Verification successful! Verified {num_users} users.\")\n",
                "\n",
                "verify_output(output_file, input_file)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
